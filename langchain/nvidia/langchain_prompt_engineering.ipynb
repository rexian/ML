{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRFcuaTri+1TUTzdJFXmPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexian/ML/blob/main/langchain/nvidia/langchain_prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "InFna9pnVuzH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain-core langgraph>0.2.27\n",
        "!pip install langchain_community langchain_huggingface\n",
        "!pip install langchain-nvidia-ai-endpoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "if not os.environ.get(\"NVIDIA_API_KEY\"):\n",
        "  os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter API key for NVIDIA AI Endpoints: \")\n",
        "nvidia_model = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVvm74hUWWu5",
        "outputId": "a0b0eef0-9193-4722-e526-9280bc7eca1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for NVIDIA AI Endpoints: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "RGW-y59MV8-n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llm_chain(model_id: str,\n",
        "                  prompt:PromptTemplate,\n",
        "                  input: str,\n",
        "                  temperature: float = 1e-3,\n",
        "                  max_length: int = 4096,\n",
        "                  do_sample: bool = True) -> str:\n",
        "    \"\"\"\n",
        "    Initializes a HuggingFaceHub with specified parameters and runs an LLMChain with a given question.\n",
        "\n",
        "    Args:\n",
        "    repo_id (str): The repository ID for the HuggingFace model.\n",
        "    temperature (float, optional): The temperature for text generation. Default is 0.5.\n",
        "    max_length (int, optional): The maximum length of the generated text. Default is 64.\n",
        "\n",
        "    Returns:\n",
        "    str: The result from running the LLMChain.\n",
        "    \"\"\"\n",
        "    # Define the prompt template within the function\n",
        "    prompt = prompt\n",
        "    llm = ChatNVIDIA(model=model_id)\n",
        "    llm_chain = prompt | llm | StrOutputParser()\n",
        "    return llm_chain.invoke({\"input\":input})"
      ],
      "metadata": {
        "id": "svTImuhlYJ62"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Avoid ambiguity\n",
        "\n",
        "- Use distinct delimiters (triple quotes, backticks, angle brackets) to separate instructions clearly."
      ],
      "metadata": {
        "id": "CpjGyb_1d-c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_summarize = f\"\"\"It's important to give clear and specific instructions \\\n",
        "when asking a model to perform a task. This will help guide the model towards \\\n",
        "the desired output, and minimize the chances of receiving irrelevant or \\\n",
        "incorrect responses. It's important to note that writing a clear prompt  \\\n",
        "doesn't necessarily mean writing a short one. In fact, longer prompts can  \\\n",
        "often provide more clarity and context for the model, resulting in more \\\n",
        "detailed and relevant outputs.\n",
        "\"\"\"\n",
        "\n",
        "template = \"\"\"Summarize the text delimited by triple backticks into a single sentence: ```{input}```.\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_examples(\n",
        "    examples=[template],\n",
        "    input_variables=[\"input\"],\n",
        "    prefix = \"<s>[INST]\",\n",
        "    suffix=\"[/INST]\"\n",
        "    )\n",
        "\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfyXJMvycUbt",
        "outputId": "1f122514-8691-4e45-c623-ba8a372aa43a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST]\n",
            "\n",
            "Summarize the text delimited by triple backticks into a single sentence: ```\u001b[33;1m\u001b[1;3m{input}\u001b[0m```.\n",
            "Summary:\n",
            "\n",
            "\n",
            "[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_model_id = \"meta/llama3-70b-instruct\"\n",
        "result = run_llm_chain(model_id = instruct_model_id,\n",
        "              prompt = prompt,\n",
        "              input = text_to_summarize)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Umt3DHkucddH",
        "outputId": "4582d22f-4948-4012-d546-ba119151f4a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When asking a model to perform a task, it is crucial to provide clear and specific instructions, which can include longer prompts that offer more context and clarity, to guide the model towards the desired output and reduce the likelihood of irrelevant responses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Request Structured Output**\n",
        "\n",
        "- Prioritize clarity: Ask for outputs in structured formats (like JSON, XML).\n",
        "\n",
        "- Structured data is simpler to interpret and use.\n",
        "\n",
        "- Defining the desired format upfront leads to more organized\n",
        "results."
      ],
      "metadata": {
        "id": "AFCRIOKyeQ8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Create some imaginary movie titles, complete with directors and genres.\n",
        "Format the information in JSON, using the keys: 'movie_id', 'title', 'director', and 'genre'.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_examples(\n",
        "    examples=[text],\n",
        "    input_variables=[],\n",
        "    prefix = \"<s>[INST]\",\n",
        "    suffix=\"[/INST]\"\n",
        "    )\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Vlo9ReeY-Q",
        "outputId": "bdc2a1fd-f439-4957-9337-a46c3358f4ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST]\n",
            "\n",
            "Create some imaginary movie titles, complete with directors and genres.\n",
            "Format the information in JSON, using the keys: 'movie_id', 'title', 'director', and 'genre'.\n",
            "\n",
            "\n",
            "[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_llm_chain(model_id = instruct_model_id,\n",
        "              prompt = prompt,\n",
        "              input = text_to_summarize)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxb2siKDesnd",
        "outputId": "1276f598-58fc-4c22-d957-d357ca583821"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 5 imaginary movie titles with directors and genres in JSON format:\n",
            "\n",
            "```\n",
            "[\n",
            "  {\n",
            "    \"movie_id\": 1,\n",
            "    \"title\": \"Echoes in the Dark\",\n",
            "    \"director\": \"Lucas Brooks\",\n",
            "    \"genre\": \"Thriller\"\n",
            "  },\n",
            "  {\n",
            "    \"movie_id\": 2,\n",
            "    \"title\": \"Stardust Serenade\",\n",
            "    \"director\": \"Ava Moreno\",\n",
            "    \"genre\": \"Romantic Sci-Fi\"\n",
            "  },\n",
            "  {\n",
            "    \"movie_id\": 3,\n",
            "    \"title\": \"Burning Inferno\",\n",
            "    \"director\": \"Jaxon Lee\",\n",
            "    \"genre\": \"Action\"\n",
            "  },\n",
            "  {\n",
            "    \"movie_id\": 4,\n",
            "    \"title\": \"The Lost City of Eldarado\",\n",
            "    \"director\": \"Evelyn Stone\",\n",
            "    \"genre\": \"Adventure\"\n",
            "  },\n",
            "  {\n",
            "    \"movie_id\": 5,\n",
            "    \"title\": \"Ghosts of Memories\",\n",
            "    \"director\": \"Rylan Patel\",\n",
            "    \"genre\": \"Horror\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "\n",
            "Let me know if you'd like me to generate more!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process for Verifying Conditions**\n",
        "\n",
        "* **Spot the Criteria**: Look for specific requirements, like a set of instructions.\n",
        "* **Assess Compliance**: Examine the text to see if it meets these criteria.\n",
        "* **Customized Reply**: React accordingly - proceed if criteria are met, or take a different route if not.\n",
        "* **Transparent Feedback**: Clearly explain if conditions were met and the logic behind your response.\n",
        "\n"
      ],
      "metadata": {
        "id": "wgpESsEVfZeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"To reset your password, first, navigate to the settings page. Click \\\n",
        "on the 'Security' tab, and then select 'Change Password.' Enter your current \\\n",
        "password, followed by your new password twice for confirmation. Click on the \\\n",
        "'Save Changes' button to update your password.\n",
        "\"\"\"\n",
        "\n",
        "input_template = \"\"\"You will be provided with text enclosed in angle brackets (<>). Determine \\\n",
        "if the text contains a procedural guide.  If it does, convert the guide into a \\\n",
        "numbered list format with a title:\n",
        "\n",
        "<Title>\n",
        "\n",
        "1. ...\n",
        "2. ...\n",
        "3. ...\n",
        "4. ...\n",
        "\n",
        "If the text does not contain a procedural guide, respond with 'No procedural guide found.'\n",
        "\n",
        "<{input}>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-OSZ6GysgFrt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_examples(\n",
        "    examples=[input_template],\n",
        "    input_variables=[\"input\"],\n",
        "    prefix = \"<s>[INST]\",\n",
        "    suffix=\"[/INST]\"\n",
        "    )\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15zkqhJXgMS7",
        "outputId": "49e8f153-7d3b-460b-8522-ac93264cee14"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST]\n",
            "\n",
            "You will be provided with text enclosed in angle brackets (<>). Determine if the text contains a procedural guide.  If it does, convert the guide into a numbered list format with a title:\n",
            "\n",
            "<Title>\n",
            "\n",
            "1. ...\n",
            "2. ...\n",
            "3. ...\n",
            "4. ...\n",
            "\n",
            "If the text does not contain a procedural guide, respond with 'No procedural guide found.'\n",
            "\n",
            "<\u001b[33;1m\u001b[1;3m{input}\u001b[0m>\n",
            "\n",
            "\n",
            "[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_llm_chain(model_id = instruct_model_id,\n",
        "              prompt = prompt,\n",
        "              input = text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yKD4ZlQgZH5",
        "outputId": "7dea5a6d-f7c3-42dc-d8fb-0561cef65cd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the converted procedural guide:\n",
            "\n",
            "**Resetting Your Password**\n",
            "\n",
            "1. Navigate to the settings page.\n",
            "2. Click on the 'Security' tab.\n",
            "3. Select 'Change Password.'\n",
            "4. Enter your current password, followed by your new password twice for confirmation.\n",
            "5. Click on the 'Save Changes' button to update your password.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strategies for Complex Queries**\n",
        "\n",
        "* Detail Steps & Format\n",
        "* Break Down Tasks\n",
        "* Logical Sequencing\n",
        "* Think Before Concluding"
      ],
      "metadata": {
        "id": "hZ-FA5PZngcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Your task is to determine if a student's solution is correct or incorrect.\\\n",
        "\n",
        "To solve the problem do the following:\n",
        "\n",
        "- First, work out your own solution to the problem including the final total.\n",
        "\n",
        "- Then compare your solution to the student's solution and evaluate if the student's\\\n",
        "solution is correct or not.\n",
        "\n",
        "Don't decide if the student's solution is correct until  you have done the problem yourself.\n",
        "\n",
        "Question: ```{input}```\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"Respond with the following format:\n",
        "\n",
        "Question: ```question here```\n",
        "\n",
        "Student's solution: ```student's solution here```\n",
        "\n",
        "Actual solution: ```steps to work out the solution and your solution here```\n",
        "\n",
        "Is the student's solution the same as actual solution just calculated:```yes or no```\n",
        "\n",
        "Student grade: ```correct or incorrect```\n",
        "\n",
        "Think step-by-step, and assess provide your solution to the question.\n",
        "\n",
        "My solution is: [/INST]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "question = \"\"\"```I'm building a solar power installation and I need help working out the financials:\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost me a flat $100k per year,\\\n",
        "and an additional $10 / square foot\n",
        "\n",
        "What is the total cost for the first year of operations as a function of the number of square feet.```\n",
        "\n",
        "Student's solution:```Let x be the size of the installation in square feet.\n",
        "\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000```\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_examples(\n",
        "    examples=[template],\n",
        "    input_variables=[\"input\"],\n",
        "    prefix = \"<s>[INST]\",\n",
        "    suffix=suffix\n",
        "    )\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZIkeGDxn49Y",
        "outputId": "8f98ad65-0973-4360-b4ee-1c6b9974fe90"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST]\n",
            "\n",
            "Your task is to determine if a student's solution is correct or incorrect.\n",
            "To solve the problem do the following:\n",
            "\n",
            "- First, work out your own solution to the problem including the final total.\n",
            "\n",
            "- Then compare your solution to the student's solution and evaluate if the student'ssolution is correct or not.\n",
            "\n",
            "Don't decide if the student's solution is correct until  you have done the problem yourself.\n",
            "\n",
            "Question: ```\u001b[33;1m\u001b[1;3m{input}\u001b[0m```\n",
            "\n",
            "\n",
            "\n",
            "Respond with the following format:\n",
            "\n",
            "Question: ```question here```\n",
            "\n",
            "Student's solution: ```student's solution here```\n",
            "\n",
            "Actual solution: ```steps to work out the solution and your solution here```\n",
            "\n",
            "Is the student's solution the same as actual solution just calculated:```yes or no```\n",
            "\n",
            "Student grade: ```correct or incorrect```\n",
            "\n",
            "Think step-by-step, and assess provide your solution to the question.\n",
            "\n",
            "My solution is: [/INST]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_llm_chain(model_id = instruct_model_id,\n",
        "              prompt = prompt,\n",
        "              input = question)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-B0dRfmoGzf",
        "outputId": "a59ce5be-6bc0-43c6-f24a-811f8cef6c86"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is my response:\n",
            "\n",
            "Question: ``I'm building a solar power installation and I need help working out the financials:\n",
            "- Land costs $100 / square foot\n",
            "- I can buy solar panels for $250 / square foot\n",
            "- I negotiated a contract for maintenance that will cost me a flat $100k per year,and an additional $10 / square foot\n",
            "\n",
            "What is the total cost for the first year of operations as a function of the number of square feet.``\n",
            "\n",
            "Student's solution: ``Let x be the size of the installation in square feet.\n",
            "\n",
            "Costs:\n",
            "1. Land cost: 100x\n",
            "2. Solar panel cost: 250x\n",
            "3. Maintenance cost: 100,000 + 100x\n",
            "\n",
            "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000``\n",
            "\n",
            "Actual solution:\n",
            "\n",
            "Let's break down the costs:\n",
            "\n",
            "1. Land cost: $100/square foot, so the total land cost is 100x\n",
            "2. Solar panel cost: $250/square foot, so the total solar panel cost is 250x\n",
            "3. Maintenance cost: $100,000 per year (fixed cost) + $10/square foot, so the total maintenance cost is 100,000 + 10x\n",
            "\n",
            "Total cost = Land cost + Solar panel cost + Maintenance cost\n",
            "= 100x + 250x + 100,000 + 10x\n",
            "= 360x + 100,000\n",
            "\n",
            "Is the student's solution the same as actual solution just calculated: ``no``\n",
            "\n",
            "Student grade: ``incorrect``\n",
            "\n",
            "The student's solution incorrectly calculated the maintenance cost as 100x instead of 10x, which led to an incorrect total cost.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "1. **Clarity is Essential**: Use clear delimiters to avoid ambiguity and ensure precise responses from the model.\n",
        "\n",
        "2. **Request Structured Output**: Ask for data in organized formats like JSON or XML for ease of interpretation and use.\n",
        "\n",
        "3. **Process for Verifying Conditions**:\n",
        "   - **Spot the Criteria**: Identify specific requirements in the text.\n",
        "   - **Assess Compliance**: Check if the text meets these criteria.\n",
        "   - **Customized Reply**: Respond based on the fulfillment of conditions.\n",
        "   - **Transparent Feedback**: Clearly communicate the outcome and reasoning.\n",
        "\n",
        "4. **Strategies for Complex Queries**:\n",
        "   - **Detail Steps & Format**: Define steps and output format for complex tasks.\n",
        "   - **Break Down Tasks**: Use step-by-step instructions for better processing.\n",
        "   - **Logical Sequencing**: Ask for a logical flow before the final answer.\n",
        "   - **Think Before Concluding**: Encourage thorough processing before conclusions.\n",
        "\n",
        "5. **Balance Context and Clarity**: Provide essential information without overloading, allowing the model to request more context if needed."
      ],
      "metadata": {
        "id": "srFPI_mWoepw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QYHR7hP5ot5z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}