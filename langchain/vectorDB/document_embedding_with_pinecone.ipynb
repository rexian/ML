{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZFVSvL26VCuHoQ5dY11/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexian/ML/blob/main/langchain/vectorDB/document_embedding_with_pinecone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhyyxDN_ESHO"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_community\n",
        "!pip install pinecone-client\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "ZDblHL17E1eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os"
      ],
      "metadata": {
        "id": "I3xqTEInFAx_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the text from PDF files"
      ],
      "metadata": {
        "id": "22rIFMGbGxbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader(\"spaul\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "BtHPFI4cGXhn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the extracted text into chunks"
      ],
      "metadata": {
        "id": "CJFXSLXcG0-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "e7BCwmTBG25H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and setup embedding"
      ],
      "metadata": {
        "id": "3y35VoJLHakK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"\"\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "Z6uSETNsHfLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Pinecode"
      ],
      "metadata": {
        "id": "ijMpVpLJHpYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')"
      ],
      "metadata": {
        "id": "H98L0U6CHsKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "# Initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_API_ENV\n",
        ")\n",
        "index_name = \"test\" # put in the name of your pinecone index here"
      ],
      "metadata": {
        "id": "1bhRDWFrH1Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create embedding for each chunk"
      ],
      "metadata": {
        "id": "6mQvXieZIFlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "wG_7OXtsH2JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an LLM wrapper"
      ],
      "metadata": {
        "id": "yLbV3aTWIXpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())\n",
        "query = 'What is Natural Language Processing?'\n",
        "qa.run(query)"
      ],
      "metadata": {
        "id": "z-uM-ALDIbBX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}