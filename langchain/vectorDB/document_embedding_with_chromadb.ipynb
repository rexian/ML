{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APax4vQhTPNe",
    "outputId": "47ccde50-04dd-4233-b177-7e2a86c8bf40"
   },
   "outputs": [],
   "source": [
    "!pip install h5py\n",
    "!pip install typing-extensions\n",
    "!pip install wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9W--wuw0RIXm",
    "outputId": "39170a6d-0998-4a35-eddb-cdd447a73f55"
   },
   "outputs": [],
   "source": [
    "!pip -q install chromadb openai tiktoken pypdf\n",
    "!pip install -U langchain-community langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jwqp-APUR1-M",
    "outputId": "c7da72b9-1534-4ac7-f20b-fde1a09af7f0"
   },
   "outputs": [],
   "source": [
    "!pip show chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMh4SF6MWSIz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3cwn7KdjXJI8"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "v2-TZbPSXu_3"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\n",
    "    \"./spaul/Deep-Learning-with-PyTorch.pdf\",\n",
    ")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9P6xmuYIZprL"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 20)\n",
    "text = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3zcS-n9Z8bR",
    "outputId": "696ef549-752c-4344-95ed-0449a8a56832"
   },
   "outputs": [],
   "source": [
    "text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DoeAkHIaZud"
   },
   "source": [
    "Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Nb_EwSQkaY8t"
   },
   "outputs": [],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents=text,\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "DE3c0qZ1bmyN"
   },
   "outputs": [],
   "source": [
    "# Persist the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lI0p8sUfbuZe",
    "outputId": "875c678b-7db7-42f2-cc87-a8ec334fc227"
   },
   "outputs": [],
   "source": [
    "# Now the persisted database can be loaded from disk\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "4dFWD0EHb5OA"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "docs = retriever.get_relevant_documents(\"What is natural language processing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ymDDFx2cU27"
   },
   "outputs": [],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3XOQLpPcapi"
   },
   "source": [
    "Extract the OpenAI API response using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fq5xU-UfcVr1",
    "outputId": "f018f31d-8c4e-45cf-9a9c-4ad5149fad88"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "llm=OpenAI()\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-bcmW_CdMXX"
   },
   "outputs": [],
   "source": [
    "# Create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sd1nrlw_dPdD"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5OatREvdVt3"
   },
   "outputs": [],
   "source": [
    "query = \"What is natural language processing?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8vj5wCQdkt2"
   },
   "source": [
    "Delete the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCY_O6VRdeE1",
    "outputId": "ffc14d27-e6be-4f84-e928-fd57161cb7d1"
   },
   "outputs": [],
   "source": [
    "!zip -r db.zip ./db\n",
    "\n",
    "# To cleanup, delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# Delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S61FDE7ed0pQ"
   },
   "source": [
    "Reload the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5tf0X-Qd2J2"
   },
   "outputs": [],
   "source": [
    "!unzip db.zip"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
