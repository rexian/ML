{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlsbyzNZh9GRzAdjj3J5lP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "348b288564bf4c08a28f04c35234ce87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4e602754cf14d57967d3358307aaf54",
              "IPY_MODEL_fb97091de82e4175aa4f5f3788ed6cce",
              "IPY_MODEL_1447fbd411714fddbb9b09b4536c147e"
            ],
            "layout": "IPY_MODEL_f1d64e60f2ce4388bf2211867b9e5cdb"
          }
        },
        "e4e602754cf14d57967d3358307aaf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d65371783624aa18ac13c00b5e4eceb",
            "placeholder": "​",
            "style": "IPY_MODEL_02844bad39a840cbacf6008f51b40d5b",
            "value": "Evaluating: 100%"
          }
        },
        "fb97091de82e4175aa4f5f3788ed6cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1049149e7640f1a5bbc0871f1171d4",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9fcccc0108f45a18151bbe553f4673f",
            "value": 15
          }
        },
        "1447fbd411714fddbb9b09b4536c147e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ed775425b74c9fa1f44cf25c1e0420",
            "placeholder": "​",
            "style": "IPY_MODEL_4ea7273777b644b89a6595f0265f4443",
            "value": " 15/15 [01:28&lt;00:00, 17.19s/it]"
          }
        },
        "f1d64e60f2ce4388bf2211867b9e5cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d65371783624aa18ac13c00b5e4eceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02844bad39a840cbacf6008f51b40d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e1049149e7640f1a5bbc0871f1171d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9fcccc0108f45a18151bbe553f4673f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08ed775425b74c9fa1f44cf25c1e0420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ea7273777b644b89a6595f0265f4443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexian/ML/blob/main/rag/evaluation/ragas_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "e64QQrtaIsxw"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -qqy langchain_google_genai\n",
        "!pip install -U -q ragas\n",
        "!pip install -U -q langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "class RAG:\n",
        "    def __init__(self, model=\"models/gemini-embedding-exp-03-07\"):\n",
        "        self.llm = GoogleGenerativeAI(google_api_key=userdata.get('GEMINI_API_KEY'), model=\"models/gemini-2.0-flash-lite\")\n",
        "        self.embeddings = GoogleGenerativeAIEmbeddings(google_api_key=userdata.get('GEMINI_API_KEY'), model=model)\n",
        "        self.doc_embeddings = None\n",
        "        self.docs = None\n",
        "\n",
        "    def load_documents(self, documents):\n",
        "        \"\"\"Load documents and compute their embeddings.\"\"\"\n",
        "        self.docs = documents\n",
        "        self.doc_embeddings = self.embeddings.embed_documents(documents)\n",
        "\n",
        "    def get_most_relevant_docs(self, query):\n",
        "        \"\"\"Find the most relevant document for a given query.\"\"\"\n",
        "        if not self.docs or not self.doc_embeddings:\n",
        "            raise ValueError(\"Documents and their embeddings are not loaded.\")\n",
        "\n",
        "        query_embedding = self.embeddings.embed_query(query)\n",
        "        similarities = [\n",
        "            np.dot(query_embedding, doc_emb)\n",
        "            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
        "            for doc_emb in self.doc_embeddings\n",
        "        ]\n",
        "        most_relevant_doc_index = np.argmax(similarities)\n",
        "        return [self.docs[most_relevant_doc_index]]\n",
        "\n",
        "    def generate_answer(self, query, relevant_doc):\n",
        "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
        "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
        "        messages = [\n",
        "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
        "            (\"human\", prompt),\n",
        "        ]\n",
        "        ai_msg = self.llm.invoke(messages)\n",
        "        return ai_msg"
      ],
      "metadata": {
        "id": "OX93VDmJRiOa"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_docs = [\n",
        "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
        "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
        "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
        "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\",\n",
        "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\"\n",
        "]"
      ],
      "metadata": {
        "id": "S6unKFViV0gs"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize RAG instance\n",
        "rag = RAG()\n",
        "\n",
        "# Load documents\n",
        "rag.load_documents(sample_docs)\n",
        "\n",
        "# Query and retrieve the most relevant document\n",
        "query = \"Who introduced the theory of relativity?\"\n",
        "relevant_doc = rag.get_most_relevant_docs(query)\n",
        "\n",
        "# Generate an answer\n",
        "answer = rag.generate_answer(query, relevant_doc)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Relevant Document: {relevant_doc}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-1LGj6MV77L",
        "outputId": "ae12fba1-8ae5-418b-b191-15433f754d2c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Who introduced the theory of relativity?\n",
            "Relevant Document: ['Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.']\n",
            "Answer: Albert Einstein proposed the theory of relativity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_queries = [\n",
        "    \"Who introduced the theory of relativity?\",\n",
        "    \"Who was the first computer programmer?\",\n",
        "    \"What did Isaac Newton contribute to science?\",\n",
        "    \"Who won two Nobel Prizes for research on radioactivity?\",\n",
        "    \"What is the theory of evolution by natural selection?\"\n",
        "]\n",
        "\n",
        "expected_responses = [\n",
        "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
        "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\",\n",
        "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
        "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
        "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\"\n",
        "]"
      ],
      "metadata": {
        "id": "WPHfV8pUk4JY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "\n",
        "for query,reference in zip(sample_queries,expected_responses):\n",
        "\n",
        "    relevant_docs = rag.get_most_relevant_docs(query)\n",
        "    response = rag.generate_answer(query, relevant_docs)\n",
        "    dataset.append(\n",
        "        {\n",
        "            \"user_input\":query,\n",
        "            \"retrieved_contexts\":relevant_docs,\n",
        "            \"response\":response,\n",
        "            \"reference\":reference\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "168TbCsJk7Aj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas import EvaluationDataset\n",
        "evaluation_dataset = EvaluationDataset.from_list(dataset)"
      ],
      "metadata": {
        "id": "wsR2usr1lCxo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "llm = GoogleGenerativeAI(google_api_key=userdata.get('GEMINI_API_KEY'), model=\"models/gemini-2.0-flash-lite\")\n",
        "evaluator_llm = LangchainLLMWrapper(llm)\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
        "\n",
        "result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "348b288564bf4c08a28f04c35234ce87",
            "e4e602754cf14d57967d3358307aaf54",
            "fb97091de82e4175aa4f5f3788ed6cce",
            "1447fbd411714fddbb9b09b4536c147e",
            "f1d64e60f2ce4388bf2211867b9e5cdb",
            "9d65371783624aa18ac13c00b5e4eceb",
            "02844bad39a840cbacf6008f51b40d5b",
            "4e1049149e7640f1a5bbc0871f1171d4",
            "a9fcccc0108f45a18151bbe553f4673f",
            "08ed775425b74c9fa1f44cf25c1e0420",
            "4ea7273777b644b89a6595f0265f4443"
          ]
        },
        "collapsed": true,
        "id": "13Wm0cAUlgKi",
        "outputId": "a8e31322-14d4-4380-9d55-8a8d3a320dc6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "348b288564bf4c08a28f04c35234ce87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 4\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 4\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 2\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 1\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 59\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 58\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 55\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 54\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 53\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 51\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 43\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 37\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash-lite\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 30\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 37\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_recall': 1.0000, 'faithfulness': 1.0000, 'factual_correctness(mode=f1)': 0.8140}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"RAGAS_APP_TOKEN\"] = \"apt.40a4-a6c56c715fc7-06f6-97d3-a3fa2e79-705ae\""
      ],
      "metadata": {
        "id": "SAzZ7Kqom93k"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K3jT4AGBts0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "D7PQDz5jnI_8",
        "outputId": "4eebecc0-44d7-402c-b163-daf54c7985ca"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results uploaded! View at https://app.ragas.io/dashboard/alignment/evaluation/257025fd-a79e-4bd7-8237-d49c13eb9b31\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://app.ragas.io/dashboard/alignment/evaluation/257025fd-a79e-4bd7-8237-d49c13eb9b31'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testset generation for RAG pipeline"
      ],
      "metadata": {
        "id": "NdlrNftotyRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/explodinggradients/Sample_Docs_Markdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1cBvsLft3nP",
        "outputId": "eda2dcb2-7568-40cd-d4ae-161a8aa2d0b4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sample_Docs_Markdown'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Total 31 (delta 0), reused 0 (delta 0), pack-reused 31 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (31/31), 131.81 KiB | 5.73 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain-community\n",
        "!pip install -U -q unstructured"
      ],
      "metadata": {
        "id": "Wq9dOJSluSMV"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "path = \"Sample_Docs_Markdown/\"\n",
        "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "_-dRpO9JxFew"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"model\": \"gemini-1.5-pro\",  # or other model IDs\n",
        "    \"temperature\": 0.4,\n",
        "    \"max_tokens\": None,\n",
        "    \"top_p\": 0.8,\n",
        "}"
      ],
      "metadata": {
        "id": "YUaYyMp-xk4Z"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "\n",
        "# Choose the appropriate import based on your API:\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize with Google AI Studio\n",
        "generator_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
        "    model=config[\"model\"],\n",
        "    temperature=config[\"temperature\"],\n",
        "    max_tokens=config[\"max_tokens\"],\n",
        "    top_p=config[\"top_p\"],\n",
        "))"
      ],
      "metadata": {
        "id": "1xpyv355xuIy"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    # Add other safety settings as needed\n",
        "}\n",
        "\n",
        "# Apply to your LLM initialization\n",
        "generator_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
        "    model=config[\"model\"],\n",
        "    temperature=config[\"temperature\"],\n",
        "    safety_settings=safety_settings,\n",
        "))"
      ],
      "metadata": {
        "id": "2zJtlEHSx6Xh"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google AI Studio Embeddings\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",  # Google's text embedding model\n",
        "    task_type=\"retrieval_document\"  # Optional: specify the task type\n",
        "))"
      ],
      "metadata": {
        "id": "hh4I0LdYyEFs"
      },
      "execution_count": 90,
      "outputs": []
    }
  ]
}