{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjgS4mwsS4wnql7vTCDL/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexian/ML/blob/main/pytorch_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXxotWetGewc",
        "outputId": "bccd797e-21dc-42af-8bf1-af44e9873d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: POSITIVE, with score: 0.9598\n",
            "label: NEGATIVE, with score: 0.9983\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "#from torch import nn\n",
        "#import torch.optim as optim\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
        "#classifier = pipeline(\"sentiment-analysis\")\n",
        "res = classifier([\"I've been waiting for a HuggingFace course my whole life.\", \"Today we have less traffic on the road\"])\n",
        "\n",
        "for result in res:\n",
        "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "classifier = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokens = tokenizer.tokenize(\"I've been waiting for a HuggingFace course my whole life.\")\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "inputs = tokenizer(\"I've been waiting for a HuggingFace course my whole life.\")\n",
        "print(f' Tokens: {tokens}')\n",
        "print(f' Token Ids: {ids}')\n",
        "print(f' Input Ids: {inputs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i53OXMo4JMfH",
        "outputId": "4fc57059-09e8-4213-ea57-38db8cfe47aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tokens: ['i', \"'\", 've', 'been', 'waiting', 'for', 'a', 'hugging', '##face', 'course', 'my', 'whole', 'life', '.']\n",
            " Token Ids: [1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]\n",
            " Input Ids: {'input_ids': [101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
        "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "print(batch)\n",
        "#\n",
        "with torch.no_grad():\n",
        "    outputs = classifier(**batch, labels=torch.tensor([1, 0]))\n",
        "    print(outputs)\n",
        "    predictions = F.softmax(outputs.logits, dim=1)\n",
        "    print(predictions)\n",
        "    labels = torch.argmax(predictions, dim=1)\n",
        "    print(labels)\n",
        "    labels = [classifier.config.id2label[label_id] for label_id in labels.tolist()]\n",
        "    print(labels)\n",
        "\n",
        "# Save pre-trained model\n",
        "save_directory = \"saved\"\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "classifier.save_pretrained(save_directory)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "classifier = AutoModelForSequenceClassification.from_pretrained(save_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rzuczv-QyNh",
        "outputId": "c9d7fd5b-414b-452a-9f53-1e61bcd70ec8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "SequenceClassifierOutput(loss=tensor(0.0208), logits=tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]]), hidden_states=None, attentions=None)\n",
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]])\n",
            "tensor([1, 0])\n",
            "['POSITIVE', 'NEGATIVE']\n"
          ]
        }
      ]
    }
  ]
}