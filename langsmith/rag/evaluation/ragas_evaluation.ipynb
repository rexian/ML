{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI+D63VO1RDzIUmaQ1XUMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexian/ML/blob/main/langsmith/rag/evaluation/ragas_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e64QQrtaIsxw"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -qqy langchain_google_genai\n",
        "!pip install -U -q ragas\n",
        "!pip install -U -q langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "class RAG:\n",
        "    def __init__(self, model=\"models/gemini-embedding-exp-03-07\"):\n",
        "        self.llm = GoogleGenerativeAI(google_api_key=userdata.get('GEMINI_API_KEY'), model=\"models/gemini-2.0-flash-lite\")\n",
        "        self.embeddings = GoogleGenerativeAIEmbeddings(google_api_key=userdata.get('GEMINI_API_KEY'), model=model)\n",
        "        self.doc_embeddings = None\n",
        "        self.docs = None\n",
        "\n",
        "    def load_documents(self, documents):\n",
        "        \"\"\"Load documents and compute their embeddings.\"\"\"\n",
        "        self.docs = documents\n",
        "        self.doc_embeddings = self.embeddings.embed_documents(documents)\n",
        "\n",
        "    def get_most_relevant_docs(self, query):\n",
        "        \"\"\"Find the most relevant document for a given query.\"\"\"\n",
        "        if not self.docs or not self.doc_embeddings:\n",
        "            raise ValueError(\"Documents and their embeddings are not loaded.\")\n",
        "\n",
        "        query_embedding = self.embeddings.embed_query(query)\n",
        "        similarities = [\n",
        "            np.dot(query_embedding, doc_emb)\n",
        "            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
        "            for doc_emb in self.doc_embeddings\n",
        "        ]\n",
        "        most_relevant_doc_index = np.argmax(similarities)\n",
        "        return [self.docs[most_relevant_doc_index]]\n",
        "\n",
        "    def generate_answer(self, query, relevant_doc):\n",
        "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
        "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
        "        messages = [\n",
        "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
        "            (\"human\", prompt),\n",
        "        ]\n",
        "        ai_msg = self.llm.invoke(messages)\n",
        "        return ai_msg"
      ],
      "metadata": {
        "id": "OX93VDmJRiOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_docs = [\n",
        "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
        "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
        "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
        "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\",\n",
        "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\"\n",
        "]"
      ],
      "metadata": {
        "id": "S6unKFViV0gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize RAG instance\n",
        "rag = RAG()\n",
        "\n",
        "# Load documents\n",
        "rag.load_documents(sample_docs)\n",
        "\n",
        "# Query and retrieve the most relevant document\n",
        "query = \"Who introduced the theory of relativity?\"\n",
        "relevant_doc = rag.get_most_relevant_docs(query)\n",
        "\n",
        "# Generate an answer\n",
        "answer = rag.generate_answer(query, relevant_doc)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Relevant Document: {relevant_doc}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "id": "H-1LGj6MV77L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_queries = [\n",
        "    \"Who introduced the theory of relativity?\",\n",
        "    \"Who was the first computer programmer?\",\n",
        "    \"What did Isaac Newton contribute to science?\",\n",
        "    \"Who won two Nobel Prizes for research on radioactivity?\",\n",
        "    \"What is the theory of evolution by natural selection?\"\n",
        "]\n",
        "\n",
        "expected_responses = [\n",
        "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
        "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\",\n",
        "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
        "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
        "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\"\n",
        "]"
      ],
      "metadata": {
        "id": "WPHfV8pUk4JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "\n",
        "for query,reference in zip(sample_queries,expected_responses):\n",
        "\n",
        "    relevant_docs = rag.get_most_relevant_docs(query)\n",
        "    response = rag.generate_answer(query, relevant_docs)\n",
        "    dataset.append(\n",
        "        {\n",
        "            \"user_input\":query,\n",
        "            \"retrieved_contexts\":relevant_docs,\n",
        "            \"response\":response,\n",
        "            \"reference\":reference\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "168TbCsJk7Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas import EvaluationDataset\n",
        "evaluation_dataset = EvaluationDataset.from_list(dataset)"
      ],
      "metadata": {
        "id": "wsR2usr1lCxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "llm = GoogleGenerativeAI(google_api_key=userdata.get('GEMINI_API_KEY'), model=\"models/gemini-2.0-flash-lite\")\n",
        "evaluator_llm = LangchainLLMWrapper(llm)\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
        "\n",
        "result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)\n",
        "result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "13Wm0cAUlgKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"RAGAS_APP_TOKEN\"] = \"\""
      ],
      "metadata": {
        "id": "SAzZ7Kqom93k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K3jT4AGBts0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.upload()"
      ],
      "metadata": {
        "id": "D7PQDz5jnI_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testset generation for RAG pipeline"
      ],
      "metadata": {
        "id": "NdlrNftotyRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/explodinggradients/Sample_Docs_Markdown"
      ],
      "metadata": {
        "id": "a1cBvsLft3nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain-community\n",
        "!pip install -U -q unstructured"
      ],
      "metadata": {
        "id": "Wq9dOJSluSMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "path = \"Sample_Docs_Markdown/\"\n",
        "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "_-dRpO9JxFew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"model\": \"gemini-1.5-pro\",  # or other model IDs\n",
        "    \"temperature\": 0.4,\n",
        "    \"max_tokens\": None,\n",
        "    \"top_p\": 0.8,\n",
        "}"
      ],
      "metadata": {
        "id": "YUaYyMp-xk4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "\n",
        "# Choose the appropriate import based on your API:\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize with Google AI Studio\n",
        "generator_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
        "    model=config[\"model\"],\n",
        "    temperature=config[\"temperature\"],\n",
        "    max_tokens=config[\"max_tokens\"],\n",
        "    top_p=config[\"top_p\"],\n",
        "))"
      ],
      "metadata": {
        "id": "1xpyv355xuIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    # Add other safety settings as needed\n",
        "}\n",
        "\n",
        "# Apply to your LLM initialization\n",
        "generator_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
        "    model=config[\"model\"],\n",
        "    temperature=config[\"temperature\"],\n",
        "    safety_settings=safety_settings,\n",
        "))"
      ],
      "metadata": {
        "id": "2zJtlEHSx6Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google AI Studio Embeddings\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",  # Google's text embedding model\n",
        "    task_type=\"retrieval_document\"  # Optional: specify the task type\n",
        "))"
      ],
      "metadata": {
        "id": "hh4I0LdYyEFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}